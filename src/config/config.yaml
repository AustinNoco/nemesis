defaults:
  - trainer: default
model: "unionai/pythia-410m-finetune-alpaca"
log_dir: "safetyfiles"
log_wandb: true
run_name: "GPTNeoX-125M-alldataset"
wandb_entity: "shahules786"
max_length: 512
per_digit_tokens: False
special_tokens:
  eos_token: "</s>"
  sep_token: "<sep>"
  pad_token: "<pad>"
datasets:
  - webgpt:
        split: "train"

  - AnthropicRLHF:
        split: "train"

validation_size: 0.1
