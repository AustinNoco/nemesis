defaults:
  - trainer: default
model: "Dahoas/pythia-125M-static-sft"
log_dir: "safetyfiles"
log_wandb: true
run_name: neox-160m-3epochs
wandb_entity: "shahules786"
max_length: 512
per_digit_tokens: False
special_tokens:
  eos_token: "</s>"
  sep_token: "<sep>"
  pad_token: "<pad>"
datasets:
  - hf_summary:
        split: ["validation","test"]
  - webgpt:
        split: "train"
validation_size: 0.1